{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07ccc57-235a-4baf-8d5b-1b9fb5688559",
   "metadata": {},
   "source": [
    "## Mitigating the Harm of Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20cfa1c-98b4-41c8-989f-16c8bbd59300",
   "metadata": {},
   "source": [
    "Recommender systems seek to suggest items to a user that they might enjoy using collaborative filtering techniques such as item-based filtering (suggesting similar items to items a user enjoyed) or user-based filtering (finding similarities between users and suggesting items that appeal to the group as a whole). The ultimate point is to keep users engaged on the platform, creating revenue for the platform either via sales or via increased consumption of advertisements. However, recommenders have the potential to serve harmful recommendations, exploiting a user’s curiosity to keep them engaged. \n",
    "\n",
    "For example, the article “Up Next: A Better Recommendation System” how a user’s research project on disinformation led their Pinterest feed to suggest harmful Islamophobic content that was created by a Russian government agency. Additionally, the article “YouTube, the Great Radicalizer” discusses how a user is served either right wing or left wing conspiracy theories based on the type of content they started with as these type of videos exploit a user’s curiosity and keep them engaged on the platform. While YouTube’s recommendation system is not always harmful, for example a user watching videos on jogging will be served videos on running marathons, it does have the potential to serve content that can radicalize a user.\n",
    "\n",
    "There does seem to be an inherent conflict on social media that can be difficult to manage as the company is incentivized to keep users engaged (rather than serving them a recommendation that can satisfy their curiosity and lead them off the platform). Companies have taken steps to try to limit the harmful impact of recommendations: for example, the Wired article discusses “Project Redirect” from Google which seeks to serve de-radicalizing YouTube videos to users who are engaging with harmful content.\n",
    "\n",
    "From a system design perspective, the paper “Harm Mitigation in Recommender Systems under User Preference Dynamics” discusses creating a recommendation system that creates a tradeoff between maximizing the click-through rate and mitigating harm. The authors create an objective function where the probability of click through rate is reduced by the probability that a user engages with harmful content, scaled by a trade-off regularization parameter (higher values correspond to prioritizing mitigating harmful content). However, this approach (and Google’s “Project Redirect”) are not foolproof as it is still up to the designer of the recommendation system to decide on the appropriate balance between recommendations and harm mitigation, and companies are not necessarily incentivized to reduce harm. \n",
    "\n",
    "Mitigating harm in recommendations is a difficult topic as it lies at the intersection of profits, incentives, and free speech. Implementing regulation on recommendation systems can be challenging given the free speech constraints. The best option is to have a variety of parties involved in the design of the recommendation system so that differing perspectives are present when implementing techniques to minimize harm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c66e76-75fa-4b86-89d6-4c9589a92f47",
   "metadata": {},
   "source": [
    "Sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f849397-21a2-498d-a5cc-e77c0bde1ae8",
   "metadata": {},
   "source": [
    "https://www.wired.com/story/creating-ethical-recommemndation-engines/\n",
    "\n",
    "https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html\n",
    "\n",
    "https://arxiv.org/abs/2406.09882"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DATA612)",
   "language": "python",
   "name": "data612"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
